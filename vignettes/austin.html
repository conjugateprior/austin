<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Will Lowe" />

<meta name="date" content="2015-04-12" />

<title>Introduction to Austin</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link href="data:text/css,body%20%7B%0A%20%20background%2Dcolor%3A%20%23fff%3B%0A%20%20margin%3A%201em%20auto%3B%0A%20%20max%2Dwidth%3A%20700px%3B%0A%20%20overflow%3A%20visible%3B%0A%20%20padding%2Dleft%3A%202em%3B%0A%20%20padding%2Dright%3A%202em%3B%0A%20%20font%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0A%20%20font%2Dsize%3A%2014px%3B%0A%20%20line%2Dheight%3A%201%2E35%3B%0A%7D%0A%0A%23header%20%7B%0A%20%20text%2Dalign%3A%20center%3B%0A%7D%0A%0A%23TOC%20%7B%0A%20%20clear%3A%20both%3B%0A%20%20margin%3A%200%200%2010px%2010px%3B%0A%20%20padding%3A%204px%3B%0A%20%20width%3A%20400px%3B%0A%20%20border%3A%201px%20solid%20%23CCCCCC%3B%0A%20%20border%2Dradius%3A%205px%3B%0A%0A%20%20background%2Dcolor%3A%20%23f6f6f6%3B%0A%20%20font%2Dsize%3A%2013px%3B%0A%20%20line%2Dheight%3A%201%2E3%3B%0A%7D%0A%20%20%23TOC%20%2Etoctitle%20%7B%0A%20%20%20%20font%2Dweight%3A%20bold%3B%0A%20%20%20%20font%2Dsize%3A%2015px%3B%0A%20%20%20%20margin%2Dleft%3A%205px%3B%0A%20%20%7D%0A%0A%20%20%23TOC%20ul%20%7B%0A%20%20%20%20padding%2Dleft%3A%2040px%3B%0A%20%20%20%20margin%2Dleft%3A%20%2D1%2E5em%3B%0A%20%20%20%20margin%2Dtop%3A%205px%3B%0A%20%20%20%20margin%2Dbottom%3A%205px%3B%0A%20%20%7D%0A%20%20%23TOC%20ul%20ul%20%7B%0A%20%20%20%20margin%2Dleft%3A%20%2D2em%3B%0A%20%20%7D%0A%20%20%23TOC%20li%20%7B%0A%20%20%20%20line%2Dheight%3A%2016px%3B%0A%20%20%7D%0A%0Atable%20%7B%0A%20%20margin%3A%201em%20auto%3B%0A%20%20border%2Dwidth%3A%201px%3B%0A%20%20border%2Dcolor%3A%20%23DDDDDD%3B%0A%20%20border%2Dstyle%3A%20outset%3B%0A%20%20border%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0A%20%20border%2Dwidth%3A%202px%3B%0A%20%20padding%3A%205px%3B%0A%20%20border%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0A%20%20border%2Dwidth%3A%201px%3B%0A%20%20border%2Dstyle%3A%20inset%3B%0A%20%20line%2Dheight%3A%2018px%3B%0A%20%20padding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0A%20%20border%2Dleft%2Dstyle%3A%20none%3B%0A%20%20border%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0A%0Ap%20%7B%0A%20%20margin%3A%200%2E5em%200%3B%0A%7D%0A%0Ablockquote%20%7B%0A%20%20background%2Dcolor%3A%20%23f6f6f6%3B%0A%20%20padding%3A%200%2E25em%200%2E75em%3B%0A%7D%0A%0Ahr%20%7B%0A%20%20border%2Dstyle%3A%20solid%3B%0A%20%20border%3A%20none%3B%0A%20%20border%2Dtop%3A%201px%20solid%20%23777%3B%0A%20%20margin%3A%2028px%200%3B%0A%7D%0A%0Adl%20%7B%0A%20%20margin%2Dleft%3A%200%3B%0A%7D%0A%20%20dl%20dd%20%7B%0A%20%20%20%20margin%2Dbottom%3A%2013px%3B%0A%20%20%20%20margin%2Dleft%3A%2013px%3B%0A%20%20%7D%0A%20%20dl%20dt%20%7B%0A%20%20%20%20font%2Dweight%3A%20bold%3B%0A%20%20%7D%0A%0Aul%20%7B%0A%20%20margin%2Dtop%3A%200%3B%0A%7D%0A%20%20ul%20li%20%7B%0A%20%20%20%20list%2Dstyle%3A%20circle%20outside%3B%0A%20%20%7D%0A%20%20ul%20ul%20%7B%0A%20%20%20%20margin%2Dbottom%3A%200%3B%0A%20%20%7D%0A%0Apre%2C%20code%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20color%3A%20%23333%3B%0A%7D%0Apre%20%7B%0A%20%20white%2Dspace%3A%20pre%2Dwrap%3B%20%20%20%20%2F%2A%20Wrap%20long%20lines%20%2A%2F%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20margin%3A%205px%200px%2010px%200px%3B%0A%20%20padding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0A%0Acode%20%7B%0A%20%20font%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0A%20%20font%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0A%20%20padding%3A%202px%200px%3B%0A%7D%0A%0Adiv%2Efigure%20%7B%0A%20%20text%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0A%20%20background%2Dcolor%3A%20%23FFFFFF%3B%0A%20%20padding%3A%202px%3B%0A%20%20border%3A%201px%20solid%20%23DDDDDD%3B%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20border%3A%201px%20solid%20%23CCCCCC%3B%0A%20%20margin%3A%200%205px%3B%0A%7D%0A%0Ah1%20%7B%0A%20%20margin%2Dtop%3A%200%3B%0A%20%20font%2Dsize%3A%2035px%3B%0A%20%20line%2Dheight%3A%2040px%3B%0A%7D%0A%0Ah2%20%7B%0A%20%20border%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0A%20%20padding%2Dtop%3A%2010px%3B%0A%20%20padding%2Dbottom%3A%202px%3B%0A%20%20font%2Dsize%3A%20145%25%3B%0A%7D%0A%0Ah3%20%7B%0A%20%20border%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0A%20%20padding%2Dtop%3A%2010px%3B%0A%20%20font%2Dsize%3A%20120%25%3B%0A%7D%0A%0Ah4%20%7B%0A%20%20border%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0A%20%20margin%2Dleft%3A%208px%3B%0A%20%20font%2Dsize%3A%20105%25%3B%0A%7D%0A%0Ah5%2C%20h6%20%7B%0A%20%20border%2Dbottom%3A%201px%20solid%20%23ccc%3B%0A%20%20font%2Dsize%3A%20105%25%3B%0A%7D%0A%0Aa%20%7B%0A%20%20color%3A%20%230033dd%3B%0A%20%20text%2Ddecoration%3A%20none%3B%0A%7D%0A%20%20a%3Ahover%20%7B%0A%20%20%20%20color%3A%20%236666ff%3B%20%7D%0A%20%20a%3Avisited%20%7B%0A%20%20%20%20color%3A%20%23800080%3B%20%7D%0A%20%20a%3Avisited%3Ahover%20%7B%0A%20%20%20%20color%3A%20%23BB00BB%3B%20%7D%0A%20%20a%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0A%20%20%20%20text%2Ddecoration%3A%20underline%3B%20%7D%0A%20%20a%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0A%20%20%20%20text%2Ddecoration%3A%20underline%3B%20%7D%0A%0A%2F%2A%20Class%20described%20in%20https%3A%2F%2Fbenjeffrey%2Ecom%2Fposts%2Fpandoc%2Dsyntax%2Dhighlighting%2Dcss%0A%20%20%20Colours%20from%20https%3A%2F%2Fgist%2Egithub%2Ecom%2Frobsimmons%2F1172277%20%2A%2F%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20Keyword%20%2A%2F%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%2F%2A%20DataType%20%2A%2F%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%2F%2A%20DecVal%20%28decimal%20values%29%20%2A%2F%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20BaseN%20%2A%2F%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20Float%20%2A%2F%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20Char%20%2A%2F%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20String%20%2A%2F%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%2F%2A%20Comment%20%2A%2F%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%2F%2A%20OtherToken%20%2A%2F%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20AlertToken%20%2A%2F%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20Function%20calls%20%2A%2F%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%2F%2A%20ErrorTok%20%2A%2F%0A%0A" rel="stylesheet" type="text/css" />

</head>

<body>



<div id="header">
<h1 class="title">Introduction to Austin</h1>
<h4 class="author"><em>Will Lowe</em></h4>
<h4 class="date"><em>2015-04-12</em></h4>
</div>


<div id="getting-data-in" class="section level2">
<h2>Getting Data In</h2>
<p>Austin works with any two dimensional matrix-like object for which <code>is.wfm</code> returns TRUE. An object is a wfm when it is indexable in two dimensions, has a complete set of row and column names, and has the dimension names ‘docs’ and ‘words’. Whether these are on rows or columns does not matter. The function <code>wfm</code> will construct a suitable object from any column and row labeled matrix-like object such as a data.frame or matrix.</p>
<p>Austin offers the helper functions <code>as.worddoc</code> and <code>as.docword</code> to extract the raw count data the appropriate way up. That is, as a matrix where words are rows and documents are columns, or where documents are rows and words are columns. The <code>docs</code> and <code>words</code> return vectors of document names and words respectively. <code>getdocs</code> is used for extracting particular sets of documents from a wfm by name or index.</p>
<p>The function <code>trim</code> can be used to remove low frequency words and words that occur in only a few documents. It can also be used to sample randomly from the set of words. This can be helpful to speed up analyses and check robustness to vocabulary choice.</p>
<div id="importing-csv-data" class="section level3">
<h3>Importing CSV Data</h3>
<p>If you already have word frequency data in a file in comma-separated value (.csv) format you can read it in using</p>
<pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">wfm</span>(<span class="st">'mydata.csv'</span>)</code></pre>
<p>This function assumes that the word labels are in the first column and document names are in the first row, pretty much as <a href="http://www.conjugateprior.org/software/jfreq">JFreq</a> would offer it to you by default. Assuming that words are rows and documents are columnsuse. If words are columns, add a <code>word.margin=2</code> argument.</p>
</div>
<div id="counting-words-from-inside-r" class="section level3">
<h3>Counting Words from Inside R</h3>
<p>Assuming Java is installed on your system then you can count words in text files and generate an appropriate <code>wfm</code> object in one step using the <code>jwordfreq</code> (Although you’ll probably have more control over the process using JFreq).</p>
</div>
</div>
<div id="scaling-with-wordfish" class="section level1">
<h1>Scaling with Wordfish</h1>
<p>Austin implements the one dimensional text scaling model Wordfish (Slapin and Proksch, 2008). When document positions are random variables the model is known as Rhetorical Ideal Points (Monroe and Maeda, 2004) which is formally equivalent to a Item Response Theory and closely related to the generalized Latent Trait models with a Poisson link, e.g. Moustaki and Knott 2000.</p>
<p>Austin implements a version of Wordfish with faster convergence, analytic or bootstrapped standard errors, and integration into R’s usual model functions, <code>summary</code>, <code>coef</code>, <code>predict</code>, etc.</p>
<p>This model class has two equivalent parameterizations: In the first, word counts are Poisson processes with means conditional on document position <code>theta</code>, word positions <code>beta</code>, document specific offsets <code>alpha</code> and word-specific offsets <code>psi</code>.</p>
<p>In the Austin implementation the parameters are estimated by a Conditional Maximum Likelihood with a regularization constraint on <code>beta</code>s that is interpretable as a shared zero mean prior with standard deviation <code>sigma</code>.</p>
<p>Alternatively, conditioning on each document’s length gives a multinomial parameterisation in terms of <code>theta</code> as before, logits of word rates using the first word as the baseline. This is the form of the model reported by Austin and used for prediction.<br />Austin treats the first parameterization as a computational convenience to make estimation more efficient. The <code>coef</code> function takes a <code>form</code> parameter if you need to see the other parameterisation.</p>
<p>We start by loading the package</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">'austin'</span>)</code></pre>
<p>and generating an (unrealistically small) set of test data according to the assumptions above</p>
<pre class="sourceCode r"><code class="sourceCode r">dd &lt;-<span class="st"> </span><span class="kw">sim.wordfish</span>(<span class="dt">docs=</span><span class="dv">10</span>, <span class="dt">vocab=</span><span class="dv">12</span>)</code></pre>
<p>The resulting object is of class <code>sim.wordfish</code> and contains the generating parameters (in the form of the first model). The two elements of interest are the vector of document positions</p>
<pre class="sourceCode r"><code class="sourceCode r">dd$theta
##  [1] -1.4863011 -1.1560120 -0.8257228 -0.4954337 -0.1651446  0.1651446
##  [7]  0.4954337  0.8257228  1.1560120  1.4863011</code></pre>
<p>and the generated data Y</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">as.worddoc</span>(dd$Y)
##      docs
## words D01 D02 D03 D04 D05 D06 D07 D08 D09 D10
##   W01  29  49  27  23  23  25  16  14   4  16
##   W02  31  35  31  24  27  22  13  15   8  12
##   W03  44  39  33  21  14  16  20  11   5   4
##   W04  10  12  14  18  19  24  25  29  33  34
##   W05   8  11  13  11  22  33  26  31  34  44
##   W06   7  14  15  23  20  22  22  29  35  33
##   W07  95  77  87  70  76  52  50  40  28  19
##   W08  96  87  85  79  66  60  46  34  28  17
##   W09  97  92  79  83  56  51  53  51  32  24
##   W10  26  25  43  49  59  64  75  88  90  99
##   W11  31  35  33  55  66  70  75  74  97 109
##   W12  26  24  40  44  52  61  79  84 106  89</code></pre>
<p>where Y is an object of class <code>wfm</code>.</p>
<p>To scale this data we use the wordfish function</p>
<pre class="sourceCode r"><code class="sourceCode r">wf &lt;-<span class="st"> </span><span class="kw">wordfish</span>(dd$Y)</code></pre>
<p>The model is by default globally identified by requiring that <code>theta[10] &gt; theta[1]</code>. This will be true for all simulated data (with more than 10 documents). For real data more suitable values may be set using the <code>dir</code> argument.</p>
<p>Estimated document positions can be summarized using</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(wf)
## Call:
##  wordfish(wfm = dd$Y)
## 
## Document Positions:
##     Estimate Std. Error    Lower    Upper
## D01  -1.3805    0.10935 -1.59483 -1.16619
## D02  -1.2281    0.10543 -1.43476 -1.02149
## D03  -0.8471    0.09784 -1.03891 -0.65538
## D04  -0.4638    0.09332 -0.64676 -0.28093
## D05  -0.1343    0.09189 -0.31438  0.04581
## D06   0.1538    0.09248 -0.02745  0.33506
## D07   0.3770    0.09413  0.19247  0.56147
## D08   0.6923    0.09830  0.49963  0.88495
## D09   1.3289    0.11364  1.10617  1.55163
## D10   1.5006    0.11949  1.26636  1.73476</code></pre>
<p>To examine the word-specific parameters use</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(wf)
## $words
##                beta          psi
## W02/W01  0.03396142 -0.023405410
## W03/W01 -0.27176818 -0.218406239
## W04/W01  0.92296123 -0.012566818
## W05/W01  1.04275702  0.006223606
## W06/W01  0.90802690  0.001725186
## W07/W01  0.02210121  0.974843742
## W08/W01 -0.02652753  0.962475635
## W09/W01  0.05028209  1.024562729
## W10/W01  0.95557050  1.017543807
## W11/W01  0.93783768  1.066872165
## W12/W01  0.99023952  0.982729757
## 
## attr(,&quot;class&quot;)
## [1] &quot;coef.wordfish&quot; &quot;list&quot;</code></pre>
<p>Estimated document positions and 95% confidence intervals can also be graphed (For more than a few tens of words the confidence intervals will probably be ‘implausibly’ small. They are nevertheless asymptotically correct given the model assumptions. It is those assumptions you might doubt.). Any unnamed second argument to the plot function is taken as a vector of true document positions. These are then plotted over the original plot, as shown in Figure~.</p>
<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-10" /></p>
<p>Positions for new documents can also be estimated. Here we generate predictions and confidence intervals for existing documents D4 and D5 in the original data set</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(wf, <span class="dt">newdata=</span><span class="kw">getdocs</span>(dd$Y, <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">5</span>)), <span class="dt">se.fit=</span><span class="ot">TRUE</span>, <span class="dt">interval=</span><span class="st">'conf'</span>)
##            fit     se.fit        lwr         upr
## D04 -0.4638455 0.09332394 -0.6467571 -0.28093395
## D05 -0.1342856 0.09188754 -0.3143818  0.04581069</code></pre>
</div>
<div id="scaling-with-wordscores" class="section level1">
<h1>Scaling with Wordscores</h1>
<p>Wordscores (Laver et al. 2003) is a method for scaling texts closely related to both correspondence analysis by implementing an incomplete reciprocal averaging algorithm, and to quadratic ordination as an approximation to an unfolding model (Lowe 2008, 2014).</p>
<p>Austin refers to the algorithm described in Laver et al. 2003 as `classic’ Wordscores to distinguish it from versions closer to correspondence analysis. A classic Wordscores analysis has several distinguishing features.</p>
<div id="classic-wordscores" class="section level2">
<h2>Classic Wordscores</h2>
<p>Classic Wordscores estimates scores for words (‘wordscores`) using only word frequency information from documents with known positions (’reference’ documents). There is therefore no iterative estimation process since document positions are observed. Documents with unknown positions (‘virgin’ documents) are treated as out of sample.</p>
<p>Positions for out of sample documents are estimated by averaging the scores of the words they contain and re-scaling in an ad-hoc fashion that has generated some discussion and various alternatives. The method also offers standard errors for the out of sample documents (These are probably incorrect – partly because the probability model from they would have to be derived is unclear and partly because they can be quite implausible in some applications).</p>
<p>To replicate the example analysis in Laver et al. we begin loading the test data</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(lbg)</code></pre>
<p>So we take a look at the word counts we’ve got to work with</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">as.docword</span>(lbg)
##     words
## docs A B  C  D  E  F   G   H   I   J   K   L   M   N   O   P   Q   R   S
##   R1 2 3 10 22 45 78 115 146 158 146 115  78  45  22  10   3   2   0   0
##   R2 0 0  0  0  0  2   3  10  22  45  78 115 146 158 146 115  78  45  22
##   R3 0 0  0  0  0  0   0   0   0   0   2   3  10  22  45  78 115 146 158
##   R4 0 0  0  0  0  0   0   0   0   0   0   0   0   0   0   2   3  10  22
##   R5 0 0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0   0
##   V1 0 0  0  0  0  0   0   2   3  10  22  45  78 115 146 158 146 115  78
##     words
## docs   T   U   V   W   X   Y   Z  ZA  ZB  ZC  ZD  ZE ZF ZG ZH ZI ZJ ZK
##   R1   0   0   0   0   0   0   0   0   0   0   0   0  0  0  0  0  0  0
##   R2  10   3   2   0   0   0   0   0   0   0   0   0  0  0  0  0  0  0
##   R3 146 115  78  45  22  10   3   2   0   0   0   0  0  0  0  0  0  0
##   R4  45  78 115 146 158 146 115  78  45  22  10   3  2  0  0  0  0  0
##   R5   0   2   3  10  22  45  78 115 146 158 146 115 78 45 22 10  3  2
##   V1  45  22  10   3   2   0   0   0   0   0   0   0  0  0  0  0  0  0</code></pre>
<p>and then fit a classic Wordscores model to them. Assume we know the positions of document R1 through R5 and wish to scale V1.</p>
<p>We first separate the reference documents from the virgin document:</p>
<pre class="sourceCode r"><code class="sourceCode r">ref &lt;-<span class="st"> </span><span class="kw">getdocs</span>(lbg, <span class="dv">1</span>:<span class="dv">5</span>)
vir &lt;-<span class="st"> </span><span class="kw">getdocs</span>(lbg, <span class="st">'V1'</span>) </code></pre>
<p>then fit the model using the reference documents</p>
<pre class="sourceCode r"><code class="sourceCode r">ws &lt;-<span class="st"> </span><span class="kw">classic.wordscores</span>(ref, <span class="dt">scores=</span><span class="kw">seq</span>(-<span class="fl">1.5</span>, <span class="fl">1.5</span>, <span class="dt">by=</span><span class="fl">0.75</span>))</code></pre>
<p>We can summarise the results</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(ws)
## Call:
##  classic.wordscores(wfm = ref, scores = seq(-1.5, 1.5, by = 0.75))
## 
## Reference Document Statistics:
## 
##    Total Min Max Mean Median Score
## R1  1000   0 158   27      0 -1.50
## R2  1000   0 158   27      0 -0.75
## R3  1000   0 158   27      0  0.00
## R4  1000   0 158   27      0  0.75
## R5  1000   0 158   27      0  1.50</code></pre>
<p>The summary presents details about the reference documents. If we want to see the wordscores that were generated we look for the model’s coefficients</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(ws)
##         Score
## A  -1.5000000
## B  -1.5000000
## C  -1.5000000
## D  -1.5000000
## E  -1.5000000
## F  -1.4812500
## G  -1.4809322
## H  -1.4519231
## I  -1.4083333
## J  -1.3232984
## K  -1.1846154
## L  -1.0369898
## M  -0.8805970
## N  -0.7500000
## O  -0.6194030
## P  -0.4507576
## Q  -0.2992424
## R  -0.1305970
## S   0.0000000
## T   0.1305970
## U   0.2992424
## V   0.4507576
## W   0.6194030
## X   0.7500000
## Y   0.8805970
## Z   1.0369898
## ZA  1.1846154
## ZB  1.3232984
## ZC  1.4083333
## ZD  1.4519231
## ZE  1.4809322
## ZF  1.4812500
## ZG  1.5000000
## ZH  1.5000000
## ZI  1.5000000
## ZJ  1.5000000
## ZK  1.5000000</code></pre>
<p>which can also be plotted.</p>
<p>We can now get a position for the virgin document</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(ws, <span class="dt">newdata=</span>vir)
## 37 of 37 words (100%) are scorable
## 
##     Score Std. Err. Rescaled  Lower  Upper
## V1 -0.448    0.0119   -0.448 -0.459 -0.437</code></pre>
<p>When more than one document is to be predicted, an ad-hoc procedure is applied by default to the predicted positions to rescale them to the same variance as the reference scores. This may or may not be what you want.</p>
</div>
<div id="correspondence-analysis" class="section level2">
<h2>Correspondence Analysis</h2>
<p>Wordscores approximates correspondence analysis, which is defined for more than one dimension. To explore this approach to document scaling you may find the <code>ca</code> or <code>anacor</code> packages useful. A rather limited subset of correspondence analysis is implemented by the MASS package’s <code>corresp</code> function.</p>
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p>Laver, Michael, and John Garry. 2000. “Estimating Policy Positions from Political Texts.” American Journal of Political Science 44(3): 619–34.</p>
<p>Lowe, Will. 2008. “Understanding Wordscores.” Political Analysis 16(4): 356–71.</p>
<p>Lowe, Will. 2013. “There’s (basically) Only One Way to Do It.” Paper presented at APSA 2013, Chicago IL. Available at <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2318543">SSRN</a>.</p>
<p>Monroe, Burt L., and Ko Maeda. 2004. “Talk’s Cheap: Text-Based Estimation of Rhetorical Ideal-Points.”</p>
<p>Moustaki, Irini, and Martin Knott. 2000. “Generalized Latent Trait Models.” Psychometrika 65(3): 391–411.</p>
<p>Slapin, Jonathan B., and Sven-Oliver Proksch. 2008. “A Scaling Model for Estimating Time-Series Party Positions from Texts.” American Journal of Political Science 52(3): 705–22.</p>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
